{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data Science Lab Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNh38OkUlov9rqHaN5/l2ut",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pctablet505/datascience-assignment/blob/main/Data_Science_Lab_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOL4nDdDL1lc"
      },
      "source": [
        "\n",
        "<center>\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/en/thumb/b/b2/Birsa_Institute_of_Technology_Sindri_logo.png/220px-Birsa_Institute_of_Technology_Sindri_logo.png\">\n",
        "<h1>Data Science Lab Assignment</h1>\n",
        "</center>\n",
        "\n",
        "\n",
        "|||\n",
        "|---|---|\n",
        "|Lab|Data Science|\n",
        "|Professor|Tapan Nayek|\n",
        "|Name|Rahul Kumar|\n",
        "|Roll Number|**1809022**|\n",
        "|Branch|Computer Science|\n",
        "|Signature|rahul kumar|\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKRVx_NIDUsw"
      },
      "source": [
        "# List of experiments\n",
        "|Sl No|Experiment|Page No|Remark|\n",
        "| :---- | :---: | :--- | :---: |\n",
        "|1. |Introduction to Python tools for data science|||\n",
        "|2.| Basic Statistics tools and Visualization tools  in Python |||\n",
        "|3.| K-means Clustering |||\n",
        "|4.| Linear Regression |||\n",
        "|5.| Logistic Regression|||\n",
        "|6.| Naive Bayesian Classifier|||\n",
        "|7.| Decision Trees|||\n",
        "|8.| Simulate Principal component analysis |||\n",
        "|9.| Compare the efficiency, precision and recall for any three algorithm with  common data set|||\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIYKFpe28nWn"
      },
      "source": [
        "# Introductioin to Python tools for data science\n",
        "**Aim:-** To demonstrate the use of different pythont tools for data science\n",
        "\n",
        "**Algorithm Used:-** None\n",
        "\n",
        "**Python Program:-**\n",
        "\n",
        "```\n",
        "# dummy code\n",
        "print(hello world)\n",
        "```\n",
        "\n",
        "**Evaluation of model metrics :-**  None in this experiment\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEKpHpdwId6P"
      },
      "source": [
        "# Naive Bayesian Classifier\n",
        "**Aim:-** To classify text data into different categories\n",
        "\n",
        "**Algorithm Used:-** Naive Bayes algorithm\n",
        "\n",
        "**Dataset Used:-** Genre Classification Dataset IMDb\n",
        "\n",
        "[https://www.kaggle.com/hijest/genre-classification-dataset-imdb?select=Genre+Classification+Dataset](https://www.kaggle.com/hijest/genre-classification-dataset-imdb?select=Genre+Classification+Dataset)\n",
        "\n",
        "\n",
        "\n",
        "**Python Program:-**\n",
        "\n",
        "```\n",
        "It has been implemented below\n",
        "```\n",
        "\n",
        "**Evaluation of model metrics :-**  Accuracy, Precision, Recall"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1IUhRt0O1MK"
      },
      "source": [
        "## Downloading the dataset and preprocessing it\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHiM-UXpQo1O",
        "outputId": "18b733e1-413e-48ea-d2db-9202ed493092"
      },
      "source": [
        "#Downloading the dataset\n",
        "%cd Downloads/Genre Classification/Genre Classification Dataset\n",
        "%pwd\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C:\\Users\\pctab\\Downloads\\Genre Classification\\Genre Classification Dataset\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'C:\\\\Users\\\\pctab\\\\Downloads\\\\Genre Classification\\\\Genre Classification Dataset'"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRTMC3h3YDoV"
      },
      "source": [
        "# import the libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from collections import namedtuple, defaultdict, Counter\n",
        "import string\n",
        "from math import log\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import nltk.tokenize as tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wu0X2mQxYatw"
      },
      "source": [
        "Movie=namedtuple('Movie',['id','name','genre','description'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F021kOg-DHPK"
      },
      "source": [
        "## Preparing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkri7CTBWdCu"
      },
      "source": [
        "# prepare the dataset\n",
        "movies={}\n",
        "\n",
        "with open('train_data.txt',encoding='utf-8') as f:\n",
        "    for x in f.readlines():\n",
        "        x=x.lower()\n",
        "        id,movie,genre,description=x.split(':::')\n",
        "        id=int(id)\n",
        "        movie=movie.strip()\n",
        "        genre=genre.strip()\n",
        "        movies[id]=Movie(id,movie,genre,description)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4PSCvpsX8x0",
        "outputId": "76857992-1170-452c-c77d-3b83938e8a1e"
      },
      "source": [
        "#download relevant nltk modules\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "#define set of stopwords\n",
        "stopwords_set=set(stopwords.words('english'))\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\pctab\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\pctab\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\pctab\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpN5C-m3DR9_"
      },
      "source": [
        "## Prepare the vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCM36hVpLjnU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o07QBKu9dCKV"
      },
      "source": [
        "# Prepare the vocabulary\n",
        "vocabulary=Counter()\n",
        "vocabulary_size=10000\n",
        "\n",
        "\n",
        "def preprocess_text(text):\n",
        "    lametizer=WordNetLemmatizer()\n",
        "    stemmer=nltk.PorterStemmer()\n",
        "    result=[]\n",
        "    words=tokenize.word_tokenize(text)\n",
        "    for word in words:\n",
        "            word=lametizer.lemmatize(word)\n",
        "            word=stemmer.stem(word)   \n",
        "            if word not in stopwords_set and word not in string.punctuation and not word.isnumeric():\n",
        "                result.append(word)\n",
        "    return result\n",
        "\n",
        "\n",
        "def prepare_vocabulary():    \n",
        "    for x in movies:\n",
        "        text=movies[x].description\n",
        "        words=preprocess_text(text)\n",
        "        for word in words:\n",
        "            vocabulary[word]+=1\n",
        "    \n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7V-QddLpHLy",
        "outputId": "ff6d066e-f794-4a3c-ccee-97839f6c2c00"
      },
      "source": [
        "%%time\n",
        "prepare_vocabulary()\n",
        "#vocabulary=Counter({word:count for word,count in vocabulary.most_common(vocabulary_size)})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wall time: 2min 33s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XPmwY9opVgd"
      },
      "source": [
        "#vocabulary"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hHCNDHlDWYn",
        "outputId": "7095e4ce-1e69-43b9-96a4-c6cf475fb918"
      },
      "source": [
        "print('Total number of words in vocabulary is :',len(vocabulary))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of words in vocabulary is : 118065\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-7VAeOYRJRW"
      },
      "source": [
        "#vocabulary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLzocFIeiDTX",
        "outputId": "583f6d44-a640-4290-c885-36409d0c022a"
      },
      "source": [
        "# the list of genres to classify the movie\n",
        "genres=set([movies[x].genre for x in movies])\n",
        "print(genres)\n",
        "print('Number of genres in the dataset is :',len(genres))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'fantasy', 'reality-tv', 'adventure', 'news', 'horror', 'animation', 'drama', 'short', 'game-show', 'western', 'crime', 'adult', 'musical', 'comedy', 'biography', 'romance', 'sport', 'talk-show', 'war', 'documentary', 'music', 'history', 'sci-fi', 'family', 'thriller', 'mystery', 'action'}\n",
            "Number of genres in the dataset is : 27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cTwmeEplVpn"
      },
      "source": [
        "# prepare the word count table\n",
        "word_count_table=defaultdict(lambda:defaultdict(int))\n",
        "\n",
        "def prepare_word_count_table():\n",
        "    for id in movies:\n",
        "        description=movies[id].description\n",
        "        genre=movies[id].genre\n",
        "        words=preprocess_text(description)\n",
        "        for word in words:\n",
        "            if word in vocabulary:          \n",
        "                word_count_table[word][genre]+=1\n",
        "                word_count_table[word]['total']+=1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45vdJT_cPYvZ",
        "outputId": "15b4bfec-b296-4aa0-96c6-23de5a7946ad"
      },
      "source": [
        "%%time\n",
        "prepare_word_count_table()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wall time: 2min 33s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUaKYcKSipRT"
      },
      "source": [
        "word_count_table\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGNsINs97SuO"
      },
      "source": [
        "## Using bayes rule to implement Naive Bayesian Classifier\n",
        "\n",
        "**Assumption :** It assumes that each event is independent of each other, which isn't true, but still works good enough to produce usable results.\n",
        "\n",
        "\n",
        "**Bayes Rule :-** \n",
        "\n",
        "$ P(A|B)=\\frac{P(B|A) \\times P(A)}{P(B)} $\n",
        "\n",
        "$ => $ $ log(P(A|B)) = log(P(B|A)) + log(P(A)) - log(P(B)) $\n",
        "\n",
        "**Log-Likelihood :-**\n",
        "\n",
        "$ log(P(Genre|w_1,w_2, ... w_n)) = \\sum_{i=1}^{n}log(P(w_i|Genre) + n \\times log(P(Genre)) - \\sum_{i=1}^{n}log(P(w_i)$\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rleH2-Rnmc5u"
      },
      "source": [
        "# Calculate the log priors\n",
        "log_priors=defaultdict(lambda:defaultdict(int))\n",
        "\n",
        "for word in vocabulary:\n",
        "    for genre in genres:\n",
        "        log_priors[word][genre]=log(word_count_table[word][genre]+1)-log(word_count_table[word]['total']+len(genres))\n",
        "\n",
        "\n",
        "\n",
        "count_genres=defaultdict(int)\n",
        "for id in movies:\n",
        "    count_genres[movies[id].genre]+=1\n",
        "\n",
        "log_priors_genre={genre:np.log(count_genres[genre]+1)-np.log(len(movies)+len(genres)) for genre in genres}\n",
        "\n",
        "total_word_counts=sum([word_count_table[x]['total'] for x in word_count_table])\n",
        "\n",
        "log_priors_words=defaultdict(float)\n",
        "\n",
        "for word in vocabulary:\n",
        "    log_priors_words[word]=np.log(vocabulary[word]/total_word_counts)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qF-xY-SdpDAv"
      },
      "source": [
        "## Make the predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55LYgROupIbk"
      },
      "source": [
        "#define the prediction function\n",
        "def softmax(log_posteriors):\n",
        "    \n",
        "    probabilities={}\n",
        "    s=sum([np.exp(x) for x in log_posteriors.values()])\n",
        "    for x in log_posteriors:\n",
        "        probabilities[x]=np.exp(log_posteriors[x])/s\n",
        "    \n",
        "    \n",
        "    print(sum(probabilities.values()))\n",
        "    print(sorted(probabilities.items(),key=lambda x:x[1],reverse=True))\n",
        "def predict(text):\n",
        "    words=preprocess_text(text.lower())\n",
        "    posteriors=defaultdict(float)\n",
        "    for word in words:\n",
        "        if word in vocabulary:\n",
        "            for genre in genres:\n",
        "                posteriors[genre]+=log_priors[word][genre]+log_priors_genre[genre]-log_priors_words[word]\n",
        "    m=float('-inf')\n",
        "    res=None\n",
        "    for genre in genres:\n",
        "        if posteriors[genre]>m:\n",
        "            m=posteriors[genre]\n",
        "            res=genre\n",
        "    return res\n",
        "    #softmax(posteriors)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6asMWUupzKi",
        "outputId": "490143e5-9264-4b97-b800-b5670199a7b3"
      },
      "source": [
        "desc='''A photographer is sailing with his wife, her sister and his nympho-maniacal model. He leaves the three women alone to get a part for his boat. A mysterious man shows up, who might be an escaped criminal the police are searching for. This doesn't alarm the three women too much, and he rapidly seduces all three of them.'''\n",
        "predict(desc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'drama'"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JN2f6yOP0fQn"
      },
      "source": [
        "## Testing the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-Lekwweyect",
        "outputId": "c587ae8f-2d79-47a2-8217-903500594590"
      },
      "source": [
        "%%time\n",
        "\n",
        "test_movies_predictions={}\n",
        "\n",
        "# Load the test data and make the predictions\n",
        "with open('test_data.txt',encoding='utf-8') as f:\n",
        "    for x in f.readlines():\n",
        "        id,name,description=x.lower().split(':::')\n",
        "        y=predict(description)\n",
        "        test_movies_predictions[int(id)]=y\n",
        "\n",
        "# Load the test data solution and check the actual values\n",
        "test_movies_actual={}\n",
        "with open('test_data_solution.txt',encoding='utf-8') as f:\n",
        "    for x in f.readlines():\n",
        "        id,name,genre,description=x.lower().split(':::')\n",
        "        test_movies_actual[int(id)]=genre.strip()\n",
        "\n",
        "\n",
        "result=[(id,test_movies_actual[id]==test_movies_predictions[id]) for id in test_movies_actual]\n",
        "\n",
        "# Calculate the accuracy\n",
        "accuracy = sum([x[1] for x in result])/len(result)\n",
        "\n",
        "\n",
        "        \n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wall time: 2min 51s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALdiyDKD5XB_",
        "outputId": "bd029085-6c6f-4e74-d872-69c729e55b46"
      },
      "source": [
        "print('Accuracy of model : {:.3f}%'.format(accuracy*100))\n",
        "truth_counts=defaultdict(int)\n",
        "prediction_counts=defaultdict(int)\n",
        "for id in test_movies_actual:\n",
        "    truth_counts[test_movies_actual[id]]+=1\n",
        "    prediction_counts[test_movies_predictions[id]]+=1\n",
        "\n",
        "\n",
        "accuracy_genrewise={}\n",
        "true_positives=defaultdict(int)\n",
        "false_positives=defaultdict(int)\n",
        "for id in test_movies_predictions:\n",
        "    if test_movies_predictions[id]==test_movies_actual[id]:\n",
        "        true_positives[test_movies_actual[id]]+=1\n",
        "    else:\n",
        "        false_positives[test_movies_predictions[id]]+=1\n",
        "accuracy_genrewise={genre:true_positives[genre]/truth_counts[genre] for genre in genres}\n",
        "\n",
        "for genre,acc in accuracy_genrewise.items():\n",
        "    print('genre: {},\\t\\t\\t accuracy: {}'.format(genre,acc))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of model : 43.280%\n",
            "genre: fantasy,\t\t\t accuracy: 0.0\n",
            "genre: reality-tv,\t\t\t accuracy: 0.0\n",
            "genre: adventure,\t\t\t accuracy: 0.0\n",
            "genre: news,\t\t\t accuracy: 0.0\n",
            "genre: horror,\t\t\t accuracy: 0.0\n",
            "genre: animation,\t\t\t accuracy: 0.0\n",
            "genre: drama,\t\t\t accuracy: 0.8971495739053776\n",
            "genre: short,\t\t\t accuracy: 0.0\n",
            "genre: game-show,\t\t\t accuracy: 0.0\n",
            "genre: western,\t\t\t accuracy: 0.0\n",
            "genre: crime,\t\t\t accuracy: 0.0\n",
            "genre: adult,\t\t\t accuracy: 0.0\n",
            "genre: musical,\t\t\t accuracy: 0.0\n",
            "genre: comedy,\t\t\t accuracy: 0.00013430029546065002\n",
            "genre: biography,\t\t\t accuracy: 0.0\n",
            "genre: romance,\t\t\t accuracy: 0.0\n",
            "genre: sport,\t\t\t accuracy: 0.0\n",
            "genre: talk-show,\t\t\t accuracy: 0.0\n",
            "genre: war,\t\t\t accuracy: 0.0\n",
            "genre: documentary,\t\t\t accuracy: 0.8586591325595602\n",
            "genre: music,\t\t\t accuracy: 0.0\n",
            "genre: history,\t\t\t accuracy: 0.0\n",
            "genre: sci-fi,\t\t\t accuracy: 0.0\n",
            "genre: family,\t\t\t accuracy: 0.0\n",
            "genre: thriller,\t\t\t accuracy: 0.0\n",
            "genre: mystery,\t\t\t accuracy: 0.0\n",
            "genre: action,\t\t\t accuracy: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnB_OFofe9SE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 861
        },
        "outputId": "e0509ee8-cc0d-4647-c8cd-eb4c250a5cae"
      },
      "source": [
        "confusion_matrix(test_movies_actual,test_movies_predictions)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13476/3669192778.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_movies_actual\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_movies_predictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32mc:\\users\\pctab\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\users\\pctab\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[0;32m    297\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m     \"\"\"\n\u001b[1;32m--> 299\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    300\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s is not supported\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\users\\pctab\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     82\u001b[0m     \"\"\"\n\u001b[0;32m     83\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m     \u001b[0mtype_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\users\\pctab\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\multiclass.py\u001b[0m in \u001b[0;36mtype_of_target\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mvalid\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 254\u001b[1;33m         raise ValueError('Expected array-like (array or non-string sequence), '\n\u001b[0m\u001b[0;32m    255\u001b[0m                          'got %r' % y)\n\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mValueError\u001b[0m: Expected array-like (array or non-string sequence), got {1: 'thriller', 2: 'comedy', 3: 'documentary', 4: 'drama', 5: 'drama', 6: 'horror', 7: 'drama', 8: 'comedy', 9: 'documentary', 10: 'drama', 11: 'drama', 12: 'drama', 13: 'drama', 14: 'drama', 15: 'short', 16: 'documentary', 17: 'comedy', 18: 'western', 19: 'documentary', 20: 'documentary', 21: 'short', 22: 'drama', 23: 'documentary', 24: 'documentary', 25: 'documentary', 26: 'documentary', 27: 'drama', 28: 'family', 29: 'sport', 30: 'horror', 31: 'western', 32: 'drama', 33: 'documentary', 34: 'comedy', 35: 'drama', 36: 'documentary', 37: 'drama', 38: 'romance', 39: 'war', 40: 'drama', 41: 'short', 42: 'game-show', 43: 'short', 44: 'documentary', 45: 'documentary', 46: 'documentary', 47: 'comedy', 48: 'comedy', 49: 'drama', 50: 'documentary', 51: 'drama', 52: 'drama', 53: 'comedy', 54: 'horror', 55: 'biography', 56: 'documentary', 57: 'drama', 58: 'adult', 59: 'comedy', 60: 'documentary', 61: 'short', 62: 'drama', 63: 'drama', 64: 'drama', 65: 'drama', 66: 'talk-show', 67: 'family', 68: 'documentary', 69: 'comedy', 70: 'comedy', 71: 'documentary', 72: 'drama', 73: 'drama', 74: 'drama', 75: 'short', 76: 'documentary', 77: 'horror', 78: 'drama', 79: 'comedy', 80: 'documentary', 81: 'documentary', 82: 'horror', 83: 'documentary', 84: 'drama', 85: 'comedy', 86: 'horror', 87: 'action', 88: 'documentary', 89: 'documentary', 90: 'action', 91: 'drama', 92: 'documentary', 93: 'documentary', 94: 'drama', 9..."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNQ-HS3Z36mN"
      },
      "source": [
        "#Evaluation of model\n",
        "After using the naive bayes classifier for **27** class classification, <br>\n",
        "we got an accuracy of **43%** which is very nice for such large number of classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRXHvK80SSTg"
      },
      "source": [
        "---\n",
        "_\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "_\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLN0G8U8SWwE"
      },
      "source": [
        "import json\n",
        "data={'log_prior_words':log_priors_words,\n",
        "      'log_prior_genres':log_priors_genre,\n",
        "      'vocabulary':vocabulary}\n",
        "data_string=json.dumps(data)\n",
        "with open('naive_bayes_data.json','w') as f:\n",
        "    json.dump(data_string,f)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8LGAIVCU3t9"
      },
      "source": [
        ""
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0pkBDKuqmQ7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}